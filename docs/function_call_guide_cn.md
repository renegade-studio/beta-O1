# MiniMax-M1 å‡½æ•°è°ƒç”¨ï¼ˆFunction Callï¼‰åŠŸèƒ½æŒ‡å—

## ğŸ“– ç®€ä»‹

MiniMax-M1 æ¨¡å‹æ”¯æŒå‡½æ•°è°ƒç”¨åŠŸèƒ½ï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿè¯†åˆ«ä½•æ—¶éœ€è¦è°ƒç”¨å¤–éƒ¨å‡½æ•°ï¼Œå¹¶ä»¥ç»“æ„åŒ–æ ¼å¼è¾“å‡ºå‡½æ•°è°ƒç”¨å‚æ•°ã€‚æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ MiniMax-M1 çš„å‡½æ•°è°ƒç”¨åŠŸèƒ½ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ä½¿ç”¨ vLLM è¿›è¡Œ Function Callsï¼ˆæ¨èï¼‰

åœ¨å®é™…éƒ¨ç½²è¿‡ç¨‹ä¸­ï¼Œä¸ºäº†æ”¯æŒç±»ä¼¼ OpenAI API çš„åŸç”Ÿ Function Callingï¼ˆå·¥å…·è°ƒç”¨ï¼‰èƒ½åŠ›ï¼ŒMiniMax-M1 æ¨¡å‹é›†æˆäº†ä¸“å± `tool_call_parser=minimax` è§£æå™¨ï¼Œä»è€Œé¿å…å¯¹æ¨¡å‹è¾“å‡ºç»“æœè¿›è¡Œé¢å¤–çš„æ­£åˆ™è§£æå¤„ç†ã€‚

#### ç¯å¢ƒå‡†å¤‡ä¸é‡æ–°ç¼–è¯‘ vLLM

ç”±äºè¯¥åŠŸèƒ½å°šæœªæ­£å¼å‘å¸ƒåœ¨ PyPI ç‰ˆæœ¬ä¸­ï¼Œéœ€åŸºäºæºç è¿›è¡Œç¼–è¯‘ã€‚ä»¥ä¸‹ä¸ºåŸºäº vLLM å®˜æ–¹ Docker é•œåƒ `vllm/vllm-openai:v0.8.3` çš„ç¤ºä¾‹æµç¨‹ï¼š

```bash
IMAGE=vllm/vllm-openai:v0.8.3
DOCKER_RUN_CMD="--network=host --privileged --ipc=host --ulimit memlock=-1 --shm-size=32gb --rm --gpus all --ulimit stack=67108864"

# è¿è¡Œ docker
sudo docker run -it -v $MODEL_DIR:$MODEL_DIR \
                    -v $CODE_DIR:$CODE_DIR \
                    --name vllm_function_call \
                    $DOCKER_RUN_CMD \
                    --entrypoint /bin/bash \
                    $IMAGE
```

#### ç¼–è¯‘ vLLM æºç 

è¿›å…¥å®¹å™¨åï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ä»¥è·å–æºç å¹¶é‡æ–°å®‰è£…ï¼š

```bash
cd $CODE_DIR
git clone https://github.com/vllm-project/vllm.git
cd vllm
pip install -e .
```

#### å¯åŠ¨ vLLM API æœåŠ¡

```bash
export SAFETENSORS_FAST_GPU=1
export VLLM_USE_V1=0

python3 -m vllm.entrypoints.openai.api_server \
--model MiniMax-M1-80k \
--tensor-parallel-size 8 \
--trust-remote-code \
--quantization experts_int8  \
--enable-auto-tool-choice \
--tool-call-parser minimax \
--chat-template vllm/examples/tool_chat_template_minimax_m1.jinja \
--max_model_len 4096 \
--dtype bfloat16 \
--gpu-memory-utilization 0.85
```

**âš ï¸ æ³¨æ„ï¼š**
- `--tool-call-parser minimax` ä¸ºå…³é”®å‚æ•°ï¼Œç”¨äºå¯ç”¨ MiniMax-M1 è‡ªå®šä¹‰è§£æå™¨
- `--enable-auto-tool-choice` å¯ç”¨è‡ªåŠ¨å·¥å…·é€‰æ‹©
- `--chat-template` æ¨¡æ¿æ–‡ä»¶éœ€è¦é€‚é… tool calling æ ¼å¼

#### Function Call æµ‹è¯•è„šæœ¬ç¤ºä¾‹

ä»¥ä¸‹ Python è„šæœ¬åŸºäº OpenAI SDK å®ç°äº†ä¸€ä¸ªå¤©æ°”æŸ¥è¯¢å‡½æ•°çš„è°ƒç”¨ç¤ºä¾‹ï¼š

```python
from openai import OpenAI
import json

client = OpenAI(base_url="http://localhost:8000/v1", api_key="dummy")

def get_weather(location: str, unit: str):
    return f"Getting the weather for {location} in {unit}..."

tool_functions = {"get_weather": get_weather}

tools = [{
    "type": "function",
    "function": {
        "name": "get_weather",
        "description": "Get the current weather in a given location",
        "parameters": {
            "type": "object",
            "properties": {
                "location": {"type": "string", "description": "City and state, e.g., 'San Francisco, CA'"},
                "unit": {"type": "string", "enum": ["celsius", "fahrenheit"]}
            },
            "required": ["location", "unit"]
        }
    }
}]

response = client.chat.completions.create(
    model=client.models.list().data[0].id,
    messages=[{"role": "user", "content": "What's the weather like in San Francisco? use celsius."}],
    tools=tools,
    tool_choice="auto"
)

print(response)

tool_call = response.choices[0].message.tool_calls[0].function
print(f"Function called: {tool_call.name}")
print(f"Arguments: {tool_call.arguments}")
print(f"Result: {get_weather(**json.loads(tool_call.arguments))}")
```

**è¾“å‡ºç¤ºä¾‹ï¼š**
```
Function called: get_weather
Arguments: {"location": "San Francisco, CA", "unit": "celsius"}
Result: Getting the weather for San Francisco, CA in celsius...
```

### æ‰‹åŠ¨è§£ææ¨¡å‹è¾“å‡º

å¦‚æœæ‚¨æ— æ³•ä½¿ç”¨ vLLM çš„å†…ç½®è§£æå™¨ï¼Œæˆ–è€…éœ€è¦ä½¿ç”¨å…¶ä»–æ¨ç†æ¡†æ¶ï¼ˆå¦‚ transformersã€TGI ç­‰ï¼‰ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ–¹æ³•æ‰‹åŠ¨è§£ææ¨¡å‹çš„åŸå§‹è¾“å‡ºã€‚è¿™ç§æ–¹æ³•éœ€è¦æ‚¨è‡ªå·±è§£ææ¨¡å‹è¾“å‡ºçš„ XML æ ‡ç­¾æ ¼å¼ã€‚

#### ä½¿ç”¨ Transformers çš„ç¤ºä¾‹

ä»¥ä¸‹æ˜¯ä½¿ç”¨ transformers åº“çš„å®Œæ•´ç¤ºä¾‹ï¼š

```python
from transformers import AutoTokenizer

def get_default_tools():
    return [
        {
          "name": "get_current_weather",
          "description": "Get the latest weather for a location",
          "parameters": {
              "type": "object", 
              "properties": {
                  "location": {
                      "type": "string", 
                      "description": "A certain city, such as Beijing, Shanghai"
                  }
              }, 
          }
          "required": ["location"],
          "type": "object"
        }
    ]

# åŠ è½½æ¨¡å‹å’Œåˆ†è¯å™¨
tokenizer = AutoTokenizer.from_pretrained(model_id)
prompt = "What's the weather like in Shanghai today?"
messages = [
    {"role": "system", "content": [{"type": "text", "text": "You are a helpful assistant created by Minimax based on MiniMax-M1 model."}]},
    {"role": "user", "content": [{"type": "text", "text": prompt}]},
]

# å¯ç”¨å‡½æ•°è°ƒç”¨å·¥å…·
tools = get_default_tools()

# åº”ç”¨èŠå¤©æ¨¡æ¿ï¼Œå¹¶åŠ å…¥å·¥å…·å®šä¹‰
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True,
    tools=tools
)

# å‘é€è¯·æ±‚ï¼ˆè¿™é‡Œä½¿ç”¨ä»»ä½•æ¨ç†æœåŠ¡ï¼‰
import requests
payload = {
    "model": "MiniMaxAI/MiniMax-M1-40k",
    "prompt": text,
    "max_tokens": 4000
}
response = requests.post(
    "http://localhost:8000/v1/completions",
    headers={"Content-Type": "application/json"},
    json=payload,
    stream=False,
)

# æ¨¡å‹è¾“å‡ºéœ€è¦æ‰‹åŠ¨è§£æ
raw_output = response.json()["choices"][0]["text"]
print("åŸå§‹è¾“å‡º:", raw_output)

# ä½¿ç”¨ä¸‹é¢çš„è§£æå‡½æ•°å¤„ç†è¾“å‡º
function_calls = parse_function_calls(raw_output)
```

## ğŸ› ï¸ å‡½æ•°è°ƒç”¨çš„å®šä¹‰

### å‡½æ•°ç»“æ„ä½“

å‡½æ•°è°ƒç”¨éœ€è¦åœ¨è¯·æ±‚ä½“ä¸­å®šä¹‰ `tools` å­—æ®µï¼Œæ¯ä¸ªå‡½æ•°ç”±ä»¥ä¸‹éƒ¨åˆ†ç»„æˆï¼š

```json
{
  "tools": [
    {
      "name": "search_web",
      "description": "æœç´¢å‡½æ•°ã€‚",
      "parameters": {
        "properties": {
          "query_list": {
            "description": "è¿›è¡Œæœç´¢çš„å…³é”®è¯ï¼Œåˆ—è¡¨å…ƒç´ ä¸ªæ•°ä¸º1ã€‚",
            "items": { "type": "string" },
            "type": "array"
          },
          "query_tag": {
            "description": "queryçš„åˆ†ç±»",
            "items": { "type": "string" },
            "type": "array"
          }
        },
        "required": [ "query_list", "query_tag" ],
        "type": "object"
      }
    }
  ]
}
```

**å­—æ®µè¯´æ˜ï¼š**
- `name`: å‡½æ•°åç§°
- `description`: å‡½æ•°åŠŸèƒ½æè¿°
- `parameters`: å‡½æ•°å‚æ•°å®šä¹‰
  - `properties`: å‚æ•°å±æ€§å®šä¹‰ï¼Œkey æ˜¯å‚æ•°åï¼Œvalue åŒ…å«å‚æ•°çš„è¯¦ç»†æè¿°
  - `required`: å¿…å¡«å‚æ•°åˆ—è¡¨
  - `type`: å‚æ•°ç±»å‹ï¼ˆé€šå¸¸ä¸º "object"ï¼‰

### æ¨¡å‹å†…éƒ¨å¤„ç†æ ¼å¼

åœ¨æ¨¡å‹å†…éƒ¨å¤„ç†æ—¶ï¼Œå‡½æ•°å®šä¹‰ä¼šè¢«è½¬æ¢ä¸ºç‰¹æ®Šæ ¼å¼å¹¶æ‹¼æ¥åˆ°è¾“å…¥æ–‡æœ¬ä¸­ï¼š

```
<begin_of_document><beginning_of_sentence>system ai_setting=MiniMax AI
MiniMax AIæ˜¯ç”±ä¸Šæµ·ç¨€å®‡ç§‘æŠ€æœ‰é™å…¬å¸ï¼ˆMiniMaxï¼‰è‡ªä¸»ç ”å‘çš„AIåŠ©ç†ã€‚<end_of_sentence>
<beginning_of_sentence>system tool_setting=tools
You are provided with these tools:
<tools>
{"name": "search_web", "description": "æœç´¢å‡½æ•°ã€‚", "parameters": {"properties": {"query_list": {"description": "è¿›è¡Œæœç´¢çš„å…³é”®è¯ï¼Œåˆ—è¡¨å…ƒç´ ä¸ªæ•°ä¸º1ã€‚", "items": {"type": "string"}, "type": "array"}, "query_tag": {"description": "queryçš„åˆ†ç±»", "items": {"type": "string"}, "type": "array"}}, "required": ["query_list", "query_tag"], "type": "object"}}
</tools>
If you need to call tools, please respond with <tool_calls></tool_calls> XML tags, and provide tool-name and json-object of arguments, following the format below:
<tool_calls>
{"name": <tool-name>, "arguments": <args-json-object>}
...
</tool_calls><end_of_sentence>
<beginning_of_sentence>user name=ç”¨æˆ·
OpenAI å’Œ Gemini çš„æœ€è¿‘ä¸€æ¬¡å‘å¸ƒä¼šéƒ½æ˜¯ä»€ä¹ˆæ—¶å€™?<end_of_sentence>
<beginning_of_sentence>ai name=MiniMax AI
```

### æ¨¡å‹è¾“å‡ºæ ¼å¼

æ¨¡å‹ä¼šä»¥ä»¥ä¸‹æ ¼å¼è¾“å‡ºå‡½æ•°è°ƒç”¨ï¼š

```xml
<think>
Okay, I will search for the OpenAI and Gemini latest release.
</think>
<tool_calls>
{"name": "search_web", "arguments": {"query_tag": ["technology", "events"], "query_list": ["\"OpenAI\" \"latest\" \"release\""]}}
{"name": "search_web", "arguments": {"query_tag": ["technology", "events"], "query_list": ["\"Gemini\" \"latest\" \"release\""]}}
</tool_calls>
```

## ğŸ“¥ æ‰‹åŠ¨è§£æå‡½æ•°è°ƒç”¨ç»“æœ

### è§£æå‡½æ•°è°ƒç”¨

å½“éœ€è¦æ‰‹åŠ¨è§£ææ—¶ï¼Œæ‚¨éœ€è¦è§£ææ¨¡å‹è¾“å‡ºçš„ XML æ ‡ç­¾æ ¼å¼ï¼š

```python
import re
import json
def parse_function_calls(content: str):
    """
    è§£ææ¨¡å‹è¾“å‡ºä¸­çš„å‡½æ•°è°ƒç”¨
    """
    function_calls = []
    
    # åŒ¹é… <tool_calls> æ ‡ç­¾å†…çš„å†…å®¹
    tool_calls_pattern = r"<tool_calls>(.*?)</tool_calls>"
    tool_calls_match = re.search(tool_calls_pattern, content, re.DOTALL)
    
    if not tool_calls_match:
        return function_calls
    
    tool_calls_content = tool_calls_match.group(1).strip()
    
    # è§£ææ¯ä¸ªå‡½æ•°è°ƒç”¨ï¼ˆæ¯è¡Œä¸€ä¸ªJSONå¯¹è±¡ï¼‰
    for line in tool_calls_content.split('\n'):
        line = line.strip()
        if not line:
            continue
            
        try:
            # è§£æJSONæ ¼å¼çš„å‡½æ•°è°ƒç”¨
            call_data = json.loads(line)
            function_name = call_data.get("name")
            arguments = call_data.get("arguments", {})
            
            function_calls.append({
                "name": function_name,
                "arguments": arguments
            })
            
            print(f"è°ƒç”¨å‡½æ•°: {function_name}, å‚æ•°: {arguments}")
            
        except json.JSONDecodeError as e:
            print(f"å‚æ•°è§£æå¤±è´¥: {line}, é”™è¯¯: {e}")
    
    return function_calls

# ç¤ºä¾‹ï¼šå¤„ç†å¤©æ°”æŸ¥è¯¢å‡½æ•°
def execute_function_call(function_name: str, arguments: dict):
    """
    æ‰§è¡Œå‡½æ•°è°ƒç”¨å¹¶è¿”å›ç»“æœ
    """
    if function_name == "get_current_weather":
        location = arguments.get("location", "æœªçŸ¥ä½ç½®")
        # æ„å»ºå‡½æ•°æ‰§è¡Œç»“æœ
        return {
            "role": "tool", 
            "content": [
              {
                "name": function_name,
                "type": "text",
                "text": json.dumps({
                    "location": location, 
                    "temperature": "25", 
                    "unit": "celsius", 
                    "weather": "æ™´æœ—"
                }, ensure_ascii=False)
              }
            ] 
          }
    elif function_name == "search_web":
        query_list = arguments.get("query_list", [])
        query_tag = arguments.get("query_tag", [])
        # æ¨¡æ‹Ÿæœç´¢ç»“æœ
        return {
            "role": "tool",
            "content": [
              {
                "name": function_name,
                "type": "text",
                "text": f"æœç´¢å…³é”®è¯: {query_list}, åˆ†ç±»: {query_tag}\næœç´¢ç»“æœ: ç›¸å…³ä¿¡æ¯å·²æ‰¾åˆ°"
              }
            ]
          }
    
    return None
```

### å°†å‡½æ•°æ‰§è¡Œç»“æœè¿”å›ç»™æ¨¡å‹

æˆåŠŸè§£æå‡½æ•°è°ƒç”¨åï¼Œæ‚¨åº”å°†å‡½æ•°æ‰§è¡Œç»“æœæ·»åŠ åˆ°å¯¹è¯å†å²ä¸­ï¼Œä»¥ä¾¿æ¨¡å‹åœ¨åç»­äº¤äº’ä¸­èƒ½å¤Ÿè®¿é—®å’Œåˆ©ç”¨è¿™äº›ä¿¡æ¯ã€‚

#### å•ä¸ªç»“æœ

å‡å¦‚æ¨¡å‹è°ƒç”¨äº† `search_web` å‡½æ•°ï¼Œæ‚¨å¯ä»¥å‚è€ƒå¦‚ä¸‹æ ¼å¼æ·»åŠ æ‰§è¡Œç»“æœï¼Œ`name` å­—æ®µä¸ºå…·ä½“çš„å‡½æ•°åç§°ã€‚

```json
{
  "role": "tool", 
  "content": [
    {
      "name": "search_web",
      "type": "text",
      "text": "test_result"
    }
  ]
}
```

å¯¹åº”å¦‚ä¸‹çš„æ¨¡å‹è¾“å…¥æ ¼å¼ï¼š
```
<beginning_of_sentence>tool name=tools
tool name: search_web
tool result: test_result
<end_of_sentence>
```

#### å¤šä¸ªç»“æœ

å‡å¦‚æ¨¡å‹åŒæ—¶è°ƒç”¨äº† `search_web` å’Œ `get_current_weather` å‡½æ•°ï¼Œæ‚¨å¯ä»¥å‚è€ƒå¦‚ä¸‹æ ¼å¼æ·»åŠ æ‰§è¡Œç»“æœï¼Œ`content`åŒ…å«å¤šä¸ªç»“æœã€‚

```json
{
  "role": "tool", 
  "content": [
    {
      "name": "search_web",
      "type": "text",
      "text": "test_result1"
    },
    {
      "name": "get_current_weather",
      "type": "text",
      "text": "test_result2"
    }
  ]
}
```

å¯¹åº”å¦‚ä¸‹çš„æ¨¡å‹è¾“å…¥æ ¼å¼ï¼š
```
<beginning_of_sentence>tool name=tools
tool name: search_web
tool result: test_result1
tool name: get_current_weather
tool result: test_result2<end_of_sentence>
```

è™½ç„¶æˆ‘ä»¬å»ºè®®æ‚¨å‚è€ƒä»¥ä¸Šæ ¼å¼ï¼Œä½†åªè¦è¿”å›ç»™æ¨¡å‹çš„è¾“å…¥æ˜“äºç†è§£ï¼Œ`name` å’Œ `text` çš„å…·ä½“å†…å®¹å®Œå…¨ç”±æ‚¨è‡ªä¸»å†³å®šã€‚

## ğŸ“š å‚è€ƒèµ„æ–™

- [MiniMax-M1 æ¨¡å‹ä»“åº“](https://github.com/MiniMaxAI/MiniMax-M1)
- [vLLM é¡¹ç›®ä¸»é¡µ](https://github.com/vllm-project/vllm)
- [vLLM Function Calling PR](https://github.com/vllm-project/vllm/pull/20297)
- [OpenAI Python SDK](https://github.com/openai/openai-python)
